{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "    return pd.read_csv(file, names=['RESOLUTION', 'CHM', 'CHD', 'IFN', 'IRN', 'OPN', 'SMQ', 'SCOH', 'SCOP', 'CMQ', 'CCOH', 'CCOP', 'SERVICES'])\n",
    "df = read_csv('398907877__AppPortal_21_07_22_06_56_K12.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "df_norm = df.copy()\n",
    "\n",
    "def normalize(df):\n",
    "    df_min = df.min()\n",
    "    df_max = df.max()\n",
    "    if df_min != df_max: \n",
    "        df = df.apply(lambda x : (x - df_min) /(df_max - df_min))\n",
    "    else:\n",
    "        df = df.apply(lambda x : 1)\n",
    "        #print(f\"[WARNING] Equal values on normalization\")\n",
    "    return df\n",
    "\n",
    "def normalize_data(df):\n",
    "    df['IFN'] = normalize(df['IFN'])\n",
    "    df['IRN'] = normalize(df['IRN'])\n",
    "    df['SMQ'] = normalize(df['SMQ'])\n",
    "    df['CMQ'] = normalize(df['CMQ'])\n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "df_norm = normalize_data(df_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust values of IFN, IRN, SCOP and CCOP to 1-x, (lower values mean better results) \n",
    "def adjust_values(df):\n",
    "    df['IFN'] = df['IFN'].apply(lambda x: 1-x)\n",
    "    df['IRN'] = df['IRN'].apply(lambda x: 1-x)\n",
    "    df['SCOP'] = df['SCOP'].apply(lambda x: 1-x)\n",
    "    df['CCOP'] = df['CCOP'].apply(lambda x: 1-x)\n",
    "    return df\n",
    "df_norm = adjust_values(df_norm)\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total(df):\n",
    "    df['TOTAL'] = (df.loc[:,'IFN':'IRN'].sum(axis=1) + df.loc[:,'SMQ'] + df.loc[:,'CMQ'])\n",
    "    df['Total'] = (0.1 * df.loc[:,'CHM']) + (0.1 * df.loc[:,'CHD']) + (0.2 * df.loc[:,'IFN']) + (0.2 * df.loc[:,'IRN']) + (0.2 * df.loc[:,'SMQ']) + (0.2 * df.loc[:,'CMQ'])\n",
    "    df['Total'] = df.loc[:,'SCOH'] + df.loc[:,'SCOP'] + df.loc[:,'CCOH'] + df.loc[:,'CCOP']\n",
    "    return df\n",
    "\n",
    "df_norm = calculate_total(df_norm)\n",
    "df_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_iteration_for_resolution(df_norm):\n",
    "    best = {}\n",
    "    drop_indexes = []\n",
    "    for index, row in df_norm.iterrows():\n",
    "        res = row['RESOLUTION']\n",
    "        total = row['TOTAL']\n",
    "\n",
    "        if res in best:\n",
    "            if total >= best[res][1]:\n",
    "                drop_indexes.append(best[res][0])\n",
    "                best[res] = (index, total)\n",
    "            else:\n",
    "                drop_indexes.append(index)\n",
    "        else:\n",
    "            best[res] = (index, total)\n",
    "\n",
    "\n",
    "    df_norm = df_norm.drop(df_norm.index[drop_indexes]).reset_index(drop=True)\n",
    "    return df_norm\n",
    "\n",
    "df_norm = choose_best_iteration_for_resolution(df_norm)\n",
    "df_norm\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df_norm):\n",
    "    x = df_norm['RESOLUTION']\n",
    "    y = df_norm['TOTAL']\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    \n",
    "    \n",
    "    ax1.plot(x,y)\n",
    "    z = np.polyfit(x, y, 3)\n",
    "    p = np.poly1d(z)\n",
    "    ax1.plot(x,p(x),'r--')\n",
    "    \n",
    "    \n",
    "    ax2.plot(x, df_norm['CHM'], label='CHM')\n",
    "    ax2.plot(x, df_norm['CHD'], label='CHD')\n",
    "    ax2.plot(x, df_norm['CMQ'], label='CMQ')\n",
    "    ax2.plot(x, df_norm['SMQ'], label='SMQ')\n",
    "    ax2.plot(x, df_norm['IRN'], label='IRN')\n",
    "    ax2.plot(x, df_norm['IFN'], label='IFN')\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "    #plt.savefig('jpetstore.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "plot(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_data = pd.read_csv('merged_data.csv')\n",
    "\n",
    "# Plot metrics\n",
    "# Read all csv\n",
    "total = 0\n",
    "csvs = []\n",
    "dir = '.'\n",
    "for cur, directories, files in os.walk(dir):\n",
    "    if cur == dir: # Current directory only\n",
    "        for f in files:\n",
    "            if 'csv' in f and 'merged_data' not in f:\n",
    "                total += 1\n",
    "                csvs.append(f)\n",
    "\n",
    "executed_projects = set()\n",
    "for f in csvs:\n",
    "    try:\n",
    "        project_name = re.split(r'_\\d', f)[0]\n",
    "        if project_name in executed_projects:\n",
    "            continue\n",
    "        executed_projects.add(project_name)\n",
    "        project_data = projects_data[projects_data.name.eq(project_name.replace('__','/'))]\n",
    "        print(f\"\\n\\n\\nMetrics for {project_name}\")\n",
    "        print(f\"Total classes: {project_data.classes.item()}\")\n",
    "        print(f\"Total controllers: {project_data.controllers.item()}\")\n",
    "        print(f\"Open issues : {project_data.open_issues.item()}\")\n",
    "        print(f\"Stars : {project_data.stars.item()}\")\n",
    "        \n",
    "\n",
    "        df = read_csv(f)\n",
    "        df = normalize_data(df)\n",
    "        df = adjust_values(df)\n",
    "        df = calculate_total(df)\n",
    "        df = choose_best_iteration_for_resolution(df)\n",
    "        plot(df)\n",
    "        print(f\"Max val resolution: {df.loc[df['TOTAL'].idxmax()].RESOLUTION}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError on {project_name}\")\n",
    "        \n",
    "# projects_data[projects_data.name.eq('AnonymousCyberWarrior/guoan_interface_1.0')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify projects and histogram\n",
    "projects = {re.split(r'_\\d', p)[0] for p in set(next(os.walk('/home/mbrito/git/thesis/data/metrics_backup'))[2]) if 'csv' in p and 'merged' not in p}\n",
    "projects_data = pd.read_csv('merged_data.csv')\n",
    "\n",
    "print(len(csvs))                \n",
    "for f in csvs:\n",
    "    try:\n",
    "        project_name = re.split(r'_\\d', f)[0]\n",
    "    except TypeError as e:\n",
    "        print(f\"[ERROR] Failed for project: {project_name}\") # should only happen for other csvs in the folder other than metrics\n",
    "\n",
    "projects = {p.replace('__', '/') for p in projects}\n",
    "final_projects = set()\n",
    "drop_indexes = []\n",
    "\n",
    "# Identify and remove the projects that did not get executed due to parser complications (projects that did not compile or had other issues)\n",
    "for index, row in projects_data.iterrows():\n",
    "    if row['name'] not in projects:        \n",
    "        drop_indexes.append(index)\n",
    "    else:\n",
    "        final_projects.add(row['name'])\n",
    "\n",
    "    \n",
    "\n",
    "# Filter out the top 10% outliers\n",
    "projects_data = projects_data.drop(projects_data.index[drop_indexes]).reset_index(drop=True)\n",
    "#q = projects_data[\"classes\"].quantile(0.9)\n",
    "# projects_hist = projects_data.loc[(projects_data.classes < q)]\n",
    "projects_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of projects by classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS ONE AS HISTOGRAM\n",
    "ran = np.arange(30,800,75)\n",
    "#ran = np.append(ran, [2600])\n",
    "print(ran)\n",
    "#plt.hist(projects_data['classes'], bins=ran, align='left',rwidth=0.8, color='steelblue')\n",
    "_, bins, patches = plt.hist(np.clip(projects_data['classes'], ran[0], ran[-1]), bins=ran, rwidth=0.9)\n",
    "\n",
    "labels = []\n",
    "it = iter(list(ran))\n",
    "min = next(it)\n",
    "for max in it:\n",
    "    print(f\"{min} {max}\")    \n",
    "    labels.append(f\"{min} -\\n{max}\")\n",
    "    min = max\n",
    "\n",
    "xlabels = bins[1:].astype(str)\n",
    "xlabels[-1] += '+'\n",
    "\n",
    "labels = labels[:-1]\n",
    "labels.append('705+')\n",
    "\n",
    "rans_2 = [r + 35 for r in ran]\n",
    "plt.xticks(rans_2, labels, fontsize=8)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Classes', labelpad=5)\n",
    "plt.xlim([0, 800])\n",
    "\n",
    "\n",
    "plt.savefig('new_histogram.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis by range of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {re.split(r'_\\d', p)[0] : p for p in set(next(os.walk('/home/mbrito/git/thesis/data/metrics'))[2]) if 'csv' in p and 'merged' not in p}\n",
    "def copy_items(df_dst, index, df_src, labels):\n",
    "    for l in labels:\n",
    "        df_dst.loc[index, l] = df_src[l].item()\n",
    "        \n",
    "for index, row in projects_data.iterrows():\n",
    "    name = row['name'].replace('/', '__')\n",
    "    if name in metrics:\n",
    "        df = read_csv(f\"/home/mbrito/git/thesis/data/metrics/{metrics[name]}\")\n",
    "        df_temp = df.copy()\n",
    "        df_temp = normalize_data(df_temp)\n",
    "        df_temp = adjust_values(df_temp)\n",
    "        \n",
    "        df_temp = calculate_total(df_temp)\n",
    "        df_temp = choose_best_iteration_for_resolution(df_temp)\n",
    "        \n",
    "        df_best = df_temp.sort_values('TOTAL', ascending=False)[0:1]\n",
    "        copy_items(projects_data, index, df.iloc[df_best.index.item()], ['RESOLUTION', 'CHM', 'CHD', 'IRN', 'IFN', 'OPN', 'CMQ', 'SMQ', 'SERVICES'])\n",
    "        \n",
    "def get_df_in_range(df, col, min, max):\n",
    "    return df[(df[col] > min) & (df[col] <= max)].sort_values(col, ascending=False)\n",
    "\n",
    "# Create the actual groups\n",
    "ran = np.arange(0,1001, 150)\n",
    "ran = np.append(ran, [1000,10000])\n",
    "\n",
    "it = iter(list(ran))\n",
    "mi = next(it)\n",
    "df_groups = []\n",
    "for ma in it:\n",
    "    #print(f\"{mi} {ma}\")\n",
    "    df_group = get_df_in_range(projects_data, 'classes', mi, ma)\n",
    "    df_groups.append(([mi,ma], df_group))\n",
    "    mi = ma    \n",
    "\n",
    "for ran, df in df_groups:\n",
    "    print(f\"Class range {ran[0]} - {ran[1]} - {len(df)} applications\")\n",
    "    df.boxplot(column=['CHM', 'CHD', 'SMQ', 'CMQ'])\n",
    "    plt.show()\n",
    "    \n",
    "projects_data.sort_values('SMQ')\n",
    "\n",
    "print(f\"Overall boxplot\")\n",
    "projects_data.boxplot(column=['CHM', 'CHD', 'SMQ', 'CMQ'])\n",
    "plt.savefig('boxplot.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_data.boxplot(column=['IFN'])\n",
    "plt.savefig('boxplot_ifn.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlance analysis \n",
    "Identify ratio of classes/methods and correlate it to metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "projects = projects_data.copy()\n",
    "project_stats_base_dir = \"/home/mbrito/git/thesis/data/projectstats\"\n",
    "error = []\n",
    "\n",
    "def get_project_data(file): \n",
    "    # print(f\"Ratio for {file}\")\n",
    "    try:\n",
    "        with open(file) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            project_total_classes = data['totalClasses']\n",
    "            project_method_declarations = 0\n",
    "            project_method_invocations = 0\n",
    "            project_total_dependencies = 0\n",
    "            project_total_unique_dependencies = 0\n",
    "            \n",
    "            for class_name, classe in data['classes'].items():\n",
    "                method_invocations = list(filter(lambda c : c != class_name, classe['methodInvocations']))               \n",
    "                project_method_declarations += classe['methodDeclarations']\n",
    "                project_method_invocations += len(method_invocations)\n",
    "                project_total_dependencies += classe['totalDependencies'] \n",
    "                project_total_unique_dependencies += classe['totalUniqueDependencies'] \n",
    "\n",
    "            if project_method_declarations == 0:\n",
    "                raise Exception(\"File does not contain any method declarations\")\n",
    "                error.append(file)\n",
    "\n",
    "            return project_total_classes, project_method_declarations, project_method_invocations, \\\n",
    "                    project_total_dependencies, project_total_unique_dependencies\n",
    "    except FileNotFoundError:\n",
    "        error.append(f\"File Not Found: {file}\")\n",
    "    \n",
    "    \n",
    "for index, row in projects.iterrows():\n",
    "    name = row['name'].replace('/','__')\n",
    "    classes, method_declarations, method_invocations, dependencies, unique_dependencies = get_project_data(f\"{project_stats_base_dir}/{name}\")\n",
    "    projects.loc[index, 'ratio1'] = classes / method_declarations\n",
    "    projects.loc[index, 'ratio2'] = classes / method_invocations \n",
    "    projects.loc[index, 'ratio3'] = classes / dependencies\n",
    "    projects.loc[index, 'ratio4'] = classes / unique_dependencies\n",
    "\n",
    "\n",
    "corr = projects.copy()\n",
    "corr = corr[corr['IRN'] < 10000] # Remove 3 huge outliers\n",
    "\n",
    "corr_variables = ['ratio1', 'ratio2',  'CHM', 'CHD', 'IRN', 'IFN', 'CMQ', 'SMQ']\n",
    "for var in corr_variables:\n",
    "    corr[var] = corr[var].pct_change()\n",
    "   \n",
    "\n",
    "plt.scatter(corr['ratio2'], corr['IRN'])\n",
    "plt.show()\n",
    "    \n",
    "corr_results = corr[corr_variables].corr(method='spearman')\n",
    "corr_results.style.background_gradient(cmap='Blues')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group metrics by ratio of external method invocations\n",
    "1. Attach method_invocations ratio to the corresponding project\n",
    "2. Create groups of ranges of ratio\n",
    "3. Boxplot of metrics for each range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in projects.iterrows():\n",
    "        name = row['name'].replace('/','__')\n",
    "        classes, method_declarations, method_invocations, dependencies, unique_dependencies = get_project_data(f\"{project_stats_base_dir}/{name}\")\n",
    "\n",
    "# ratio4 represents ratio of classes / method_invocatoins @ cell 48 \n",
    "stats = projects['ratio4'].describe()\n",
    "# Range created according to quartiles of ratio4\n",
    "ranges = [[stats['min'],stats['25%']], [stats['25%'],stats['50%']], [stats['50%'],stats['75%']], [stats['75%'], stats['max']]]\n",
    "for r in ranges:\n",
    "    projects_range = get_df_in_range(projects, 'ratio4', r[0], r[1])\n",
    "    print(f\"Range {r[0]} - {r[1]} - project count: {len(projects_range)}\")\n",
    "    projects_range.boxplot(column=['CHM', 'CHD', 'SMQ', 'CMQ'])\n",
    "    plt.show()\n",
    "    projects_range.boxplot(column=['IFN'])\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects[projects['IRN'] < 10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr['IRN'].hist(bins=25)\n",
    "corr['ratio2'].hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit1ad0b080370d429480eff04d10e35c45"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
